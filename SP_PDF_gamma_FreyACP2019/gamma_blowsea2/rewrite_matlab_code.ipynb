{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'A', 'None', 'F', 'MU', 'N', 'Ntot', 'Q', 'Qi', 'RH10m', 'RH2m', 'RH6m', 'SP_data', 'T', 'T10m', 'T10m_ex', 'T29m_PS', 'T2m', 'T6m', 'U10m', 'U10m_ex', 'U2m', 'U39m_PS', 'U6m', 'U8cm_ex', 'dp_bins', 'filename', 'fname', 'jday', 'lat', 'lon', 'meanD', 'mu', 'p', 'q', 'rho_ice', 'snow_depth', 't', 't_NOAA', '__function_workspace__'])\n",
      "velocities are = [ 5.25 10.25 15.05]\n",
      "velocity_index =  [0, 50, 98]\n",
      "new_v_vector =  [ 5.3  5.4  5.5  5.6  5.7  5.8  5.9  6.   6.1  6.2  6.3  6.4  6.5  6.6\n",
      "  6.7  6.8  6.9  7.   7.1  7.2  7.3  7.4  7.5  7.6  7.7  7.8  7.9  8.\n",
      "  8.1  8.2  8.3  8.4  8.5  8.6  8.7  8.8  8.9  9.   9.1  9.2  9.3  9.4\n",
      "  9.5  9.6  9.7  9.8  9.9 10.  10.1 10.2 10.3 10.4 10.5 10.6 10.7 10.8\n",
      " 10.9 11.  11.1 11.2 11.3 11.4 11.5 11.6 11.7 11.8 11.9 12.  12.1 12.2\n",
      " 12.3 12.4 12.5 12.6 12.7 12.8 12.9 13.  13.1 13.2 13.3 13.4 13.5 13.6\n",
      " 13.7 13.8 13.9 14.  14.1 14.2 14.3 14.4 14.5 14.6 14.7 14.8 14.9 15.\n",
      " 15.1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "\n",
    "path = '/Users/ananth/Desktop/bas_scripts/DATA_SETS/mosaic/newdata_with_metcity/'\n",
    "filename = 'U1104_8cm_1min.mat'\n",
    "\n",
    "# read a .mat file in python\n",
    "data = sio.loadmat(path+filename)\n",
    "print(data.keys())\n",
    "\n",
    "velocity_bins = np.arange(5.25,15.25,0.1)\n",
    "velocity_index = [0, int(len(velocity_bins)/2),(len(velocity_bins)-2)]\n",
    "\n",
    "print('velocities are =', velocity_bins[velocity_index])\n",
    "print('velocity_index = ', velocity_index)\n",
    "\n",
    "new_v_vector = []\n",
    "\n",
    "for p in range(len(velocity_bins)-1):\n",
    "#for p in velocity_index:  # this line is for later when i want only a few bins \n",
    "    vbin_mean = (velocity_bins[p]+velocity_bins[p+1])/2\n",
    "    new_v_vector = np.append(new_v_vector,vbin_mean)\n",
    "    \n",
    "print('new_v_vector = ', new_v_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ananth/miniconda3/envs/tensorflow_env/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# estimate the new 8cm velocity \n",
    "U10m = data['U10m_ex']\n",
    "\n",
    "# calculate mean diameter \n",
    "N_a = data['N']\n",
    "dp_a = data['dp_bins'][:,2]\n",
    "dp_mean = np.zeros((len(N_a),1))\n",
    "sum_a = 0\n",
    "sum_b = 0\n",
    "\n",
    "sum_a = np.sum(N_a * dp_a, axis=1)\n",
    "sum_b = np.sum(N_a, axis=1)\n",
    "dp_mean_2 = sum_a / sum_b\n",
    "\n",
    "\n",
    "\n",
    "dp_mean_arr = []\n",
    "dp_25_arr = []\n",
    "dp_75_arr = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "for i in range(len(velocity_bins)-1):\n",
    "    #flag = np.where((U10m>=velocity_bins[i]) & (U10m<velocity_bins[i+1]))\n",
    "\n",
    "    n = np.where((U10m>=velocity_bins[i]) & (U10m<velocity_bins[i+1]) & (dp_mean_2!=np.NaN))\n",
    "    dp_mean_arr = np.append(dp_mean_arr,np.mean(dp_mean_2[n]))\n",
    "    dp_25_arr = np.append(dp_25_arr,np.percentile(dp_mean_2[n],25))\n",
    "    dp_75_arr = np.append(dp_75_arr,np.percentile(dp_mean_2[n],75))\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for i = 1:(length(velocity_bins)-1)\n",
    "\n",
    "    %n = find(DATA.t(:,1)>=t1 & DATA.t(:,1)<t2);\n",
    "    % below line is taking into account the 8cm wind speed\n",
    "    %n = find(DATA.U8cm_ex(:,1)>=velocity_bins(i) & DATA.U8cm_ex(:,1)<velocity_bins(i+1));\n",
    "\n",
    "    n = find(U2_2>=velocity_bins(i) & U2_2<velocity_bins(i+1));\n",
    "    % below line is for the 2m wind speed \n",
    "    %n = find(DATA.U2m(:,1)>=velocity_bins(i) & DATA.U2m_ex(:,1)<velocity_bins(i+1));\n",
    "\n",
    "    num_points = [num_points length(n)];\n",
    "\n",
    "    nonnan_count = nnz(~isnan(DATA.N(n)));\n",
    "    uncertainty_of_mean = [uncertainty_of_mean nanstd(DATA.N(n))/sqrt(nonnan_count)]\n",
    "    % 2) example diamond dust/ snow crystals\n",
    "    % diamond dust #1 observed at 29/07/13 21:38\n",
    "    % t1 = datenum('29-Jul-2013 20:00'); t2 = datenum('29-Jul-2013 23:00');\n",
    "    % diamond dust #2 observed at 30/07/13 9:15\n",
    "    % t1 = datenum('30-Jul-2013 7:30'); t2 = datenum('30-Jul-2013 10:30');\n",
    "    %% x-data: 64 SPC particle size bins\n",
    "    x = DATA.dp_bins(:,3)'; % dp in micron\n",
    "    binWidth = DATA.dp_bins(:,4)'; % binwidth in micron\n",
    "    % remove bottom & top bin of spc number densities because spurious particle detection\n",
    "    x(1) = []; x(end) = [];\n",
    "    binWidth(1) = []; binWidth(end) = [];\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ananth/miniconda3/envs/tensorflow_env/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "sum_a = np.sum(N_a * dp_a, axis=1)\n",
    "sum_b = np.sum(N_a, axis=1)\n",
    "dp_mean_2 = sum_a / sum_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m6/qj3v2qcs35d7x8gdhqzsc7280000gn/T/ipykernel_97455/3993104140.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# are they the dp_mean and dp_mean_2 the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdp_mean_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# are they the dp_mean and dp_mean_2 the same \n",
    "np.allclose(dp_mean, dp_mean_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = np.array([0,12,2])\n",
    "b1 = np.array([1,2,3])\n",
    "c1 = np.array([0,12,2])\n",
    "np.allclose(a1,c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "xw = np.random.randn(3,3,3)\n",
    "xw[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xw"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
